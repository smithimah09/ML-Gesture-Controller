{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d71de6-932e-4b22-862d-ed7295e58043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c96a55b-dd23-4a39-a16e-4c47348d7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_gesture(dir, gesture_dir, ges, num_frames):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Webcam was not opened successfully.\")\n",
    "\n",
    "    # starting the data collection process\n",
    "    try:\n",
    "        frame_count = 0\n",
    "        i = 0\n",
    "        while i < 2:\n",
    "            full_dir_path = os.path.join(dir, gesture_dir)            \n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # If frame is read correctly, succesful_ret is True\n",
    "            if not ret:\n",
    "                print(\"Can't receive frame.\")\n",
    "                break\n",
    "            \n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # Process the ROI, save the frame\n",
    "            roi = frame[100:400, 320:620]\n",
    "            roi = cv2.resize(roi, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "            cv2.imshow('Processed Frame', roi)\n",
    "            \n",
    "            # Draw rectangle for ROI and display the frame with the ROI\n",
    "            copy = frame.copy()\n",
    "            cv2.rectangle(copy, (320, 100), (620, 400), (255, 0, 0), 5)\n",
    "\n",
    "            if i == 0:\n",
    "                frame_count = 0\n",
    "                cv2.putText(copy, \"Hit [ENTER] When Ready To Record!\", (10,80), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 1)\n",
    "            if i == 1 and frame_count < num_frames:\n",
    "                frame_count += 1\n",
    "                cv2.putText(copy, f\"Recording {ges} - Train\", (10,80), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 1)\n",
    "                cv2.putText(copy, str(frame_count), (10,420), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 3)\n",
    "                img_name = os.path.join(full_dir_path, f\"{frame_count}.jpg\")\n",
    "                cv2.imwrite(img_name, roi)\n",
    "            elif frame_count == num_frames: \n",
    "                cv2.putText(copy, \"Hit [ENTER] To Exit!\", (10,80), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 1)\n",
    "            cv2.imshow('Frame', copy)\n",
    "            if cv2.waitKey(1) == 13:\n",
    "                frame_count = 0\n",
    "                i += 1\n",
    "\n",
    "    finally:\n",
    "        # Release the VideoCapture object and close display window\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f40cbc-1dd9-4bd7-aa36-376ef8e3be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_gesture(\"hand_gestures_ds/valid\", \"valid_Rindex_down\", \"Right Index Down\", 175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bee7f2-b753-4c46-9e87-b6ebb9286cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define your data augmentation parameters\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,       # Random rotation between -20 to 20 degrees\n",
    "    width_shift_range=0.2,   # Random horizontal shift\n",
    "    height_shift_range=0.2,  # Random vertical shift\n",
    "    shear_range=0.2,         # Shear transformation\n",
    "    zoom_range=0.2,          # Random zoom\n",
    "    fill_mode='nearest'      # Strategy for filling in newly created pixels\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"/Users/smithimahendran/Downloads/ML-Gesture-Controller/hand_gestures_ds/train\",\n",
    "    target_size=(256,256),\n",
    "    batch_size=32,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    \"/Users/smithimahendran/Downloads/ML-Gesture-Controller/hand_gestures_ds/valid\",\n",
    "    target_size=(256,256),\n",
    "    batch_size=32,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c24121-78f9-447f-8f51-406a3edda68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6718ff4c-f766-4801-be0d-7158fe85f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_dir contents:\n",
      "['train_Rindex_up', 'train_Rthumbs_down', 'train_Rthumbs_up', 'train_Rindex_down']\n",
      "\n",
      "First class folder contents:\n",
      "['63.jpg', '189.jpg', '77.jpg', '162.jpg', '176.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"train_data_dir contents:\")\n",
    "print(os.listdir(\"/Users/smithimahendran/Downloads/ML-Gesture-Controller/hand_gestures_ds/train\"))\n",
    "\n",
    "# List subfolders under the first class (should contain images)\n",
    "first_class_dir = os.path.join(\"/Users/smithimahendran/Downloads/ML-Gesture-Controller/hand_gestures_ds/train\", os.listdir(\"/Users/smithimahendran/Downloads/ML-Gesture-Controller/hand_gestures_ds/train\")[0])\n",
    "print(\"\\nFirst class folder contents:\")\n",
    "print(os.listdir(first_class_dir)[:5])  # Preview a few files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c52dc82d-274f-4c72-b1a7-10ec7c1f9f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 corrupted or unreadable files\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "broken = []\n",
    "for root, _, files in os.walk(\"/Users/smithimahendran/Downloads/ML-Gesture-Controller/hand_gestures_ds/train\"):\n",
    "    for f in files:\n",
    "        if not f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "        try:\n",
    "            Image.open(os.path.join(root, f)).verify()\n",
    "        except Exception:\n",
    "            broken.append(os.path.join(root, f))\n",
    "\n",
    "print(f\"Found {len(broken)} corrupted or unreadable files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674ad98a-6216-4651-bcf1-adbc4cd4c21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path exists? True\n",
      "Valid path exists? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Train path exists?\", os.path.exists(\"/Users/smithimahendran/Downloads/ML-Gesture-Controller/hand_gestures_ds/train\"))\n",
    "print(\"Valid path exists?\", os.path.exists(\"/Users/smithimahendran/Downloads/ML-Gesture-Controller/hand_gestures_ds/valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158b6658-498d-4eb2-b2af-2c7a88bc905a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_gen \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m      2\u001b[0m     train_data_dir,\n\u001b[1;32m      3\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      5\u001b[0m     classes\u001b[38;5;241m=\u001b[39m[os\u001b[38;5;241m.\u001b[39mlistdir(train_data_dir)[\u001b[38;5;241m0\u001b[39m]],  \u001b[38;5;66;03m# Load only 1 class\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_datagen' is not defined"
     ]
    }
   ],
   "source": [
    "test_gen = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    classes=[os.listdir(train_data_dir)[0]],  # Load only 1 class\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf07ff-92ef-49e5-a235-4086fb526477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
